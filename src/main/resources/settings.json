[
  {
    "name": "baseline",
    "stride": 1,
    "kernel": [3, 3],
    "maxPoolSize": [2, 2],
    "optimizer": "adam",
    "learningRate": 0.001,
    "convLayers": 2,
    "denseUnits": [128],
    "activation": "relu",
    "batchSize": 32,
    "dropout": 0.3
  },
  {
    "name": "deep_slow",
    "stride": 1,
    "kernel": [5, 5],
    "maxPoolSize": [2, 2],
    "optimizer": "sgd",
    "learningRate": 0.01,
    "convLayers": 3,
    "denseUnits": [256, 128],
    "activation": "relu",
    "batchSize": 64,
    "dropout": 0.5
  },
  {
    "name": "light_fast",
    "stride": 2,
    "kernel": [3, 3],
    "maxPoolSize": [3, 3],
    "optimizer": "rmsprop",
    "learningRate": 0.0005,
    "convLayers": 1,
    "denseUnits": [64],
    "activation": "leakyrelu",
    "batchSize": 32,
    "dropout": 0.2
  },
  {
    "name": "balanced_relu",
    "stride": 1,
    "kernel": [3, 3],
    "maxPoolSize": [2, 2],
    "optimizer": "adam",
    "learningRate": 0.0001,
    "convLayers": 2,
    "denseUnits": [256],
    "activation": "relu",
    "batchSize": 64,
    "dropout": 0.4
  },
  {
    "name": "regularized_heavy",
    "stride": 1,
    "kernel": [5, 5],
    "maxPoolSize": [2, 2],
    "optimizer": "adam",
    "learningRate": 0.001,
    "convLayers": 3,
    "denseUnits": [512, 256],
    "activation": "relu",
    "batchSize": 32,
    "dropout": 0.5
  },
  {
    "name": "wider_sparse",
    "stride": 1,
    "kernel": [3, 3],
    "maxPoolSize": [2, 2],
    "optimizer": "adam",
    "learningRate": 0.0005,
    "convLayers": 2,
    "denseUnits": [512, 256],
    "activation": "relu",
    "batchSize": 128,
    "dropout": 0.6
  },
  {
    "name": "small_deep_sgd",
    "stride": 1,
    "kernel": [3, 3],
    "maxPoolSize": [2, 2],
    "optimizer": "sgd",
    "learningRate": 0.005,
    "convLayers": 4,
    "denseUnits": [128],
    "activation": "relu",
    "batchSize": 32,
    "dropout": 0.4
  },
  {
    "name": "minimal_fast_rmsprop",
    "stride": 1,
    "kernel": [3, 3],
    "maxPoolSize": [3, 3],
    "optimizer": "rmsprop",
    "learningRate": 0.01,
    "convLayers": 1,
    "denseUnits": [32],
    "activation": "relu",
    "batchSize": 16,
    "dropout": 0.1
  }
]
